{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "# A TensorFlow regression model to predict house values\n\nThis notebook guides you through the basic concepts to construct a linear regression model with the\nTensorFlow library in Watson Studio, including how to import the predictive data, train the model to predict\nmedian housing value, and save the model to use for future inference.\n\nSome familiarity with Python is recommended. This notebook runs on Python 2 with Spark 2.1.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Table of contents\n\n1. [Import the Data](#read-data)<br>\n2. [Train the Model](#train)<br>\n    a. [Save the Machine Learned Model to a local data set](#save)<br>\n    b. [Restore the Machine Learned Model from the local data set](#restore)<br>\n3. [Infer by using the Restored Machine Learned Model](#infer)<br>\n4. [Measure the Quality of the Trained Model](#measurement)<br>\n5. [Summary](#summary)<br>\n    a. [Related Links](#links)<br>\n    b. [Author Information](#author)<br>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div class=\"alert alert-block alert-info\">\n<b>Term:</b> 'Tensor' means n-dimensional array, and TensorFlow is a library\nthat makes it easy to specify a computational 'flow' of tensors to\nrun that flow in the most efficient way possible given the available compute power. </div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"read-data\"></a>\n## Import the Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "As a prerequisite, you must prepare a CSV file that you would like to use the\nregression model predictor on.\n\nTo provide an example, a CSV file was downloaded from the same source as the\n`scikit learn fetch_california_housing()` method. The result yielded a CSV\nfile `cal_housing_data with headers.csv` with a sample data set that maps house\nprices to several predictor variables\nsuch as house age, number of bedrooms, and municipal population. The sample data\nin a CSV file is available for download onto your personal computer at [John\nBoyer's GitHub repo](https://github.com/john-boyer-phd/TensorFlow-\nSamples/tree/master/Linear%20Regression).\n\nTo load the CSV file, open the **Files** window by clicking on the binary icon in the upper right corner and upload the file. Then, select the empty cell below and click Insert to code, and then Insert Pandas DataFrame into the empty cell below. After the code is loaded, the cell can be run to read the CSV file.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @empty_cell: delete this comment and insert the CSV file dataframe in this cell\n\n#import pandas as pd\n#df_data_1 = pd.read_csv('../../cal_housing_data with headers.csv')\n#Please change last two lines to 'df_data_1...' rather than any other dataframe name\n", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "1"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 1, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "   Longitude  Latitude  HousingMedianAge  TotalRooms  TotalBedrooms  \\\n0    -122.23     37.88                41         880            129   \n1    -122.22     37.86                21        7099           1106   \n2    -122.24     37.85                52        1467            190   \n3    -122.25     37.85                52        1274            235   \n4    -122.25     37.85                52        1627            280   \n\n   Population  Households  MedianIncomeValue  MedianHouseValue  \n0         322         126             8.3252            452600  \n1        2401        1138             8.3014            358500  \n2         496         177             7.2574            352100  \n3         558         219             5.6431            341300  \n4         565         259             3.8462            342200  ", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude</th>\n      <th>Latitude</th>\n      <th>HousingMedianAge</th>\n      <th>TotalRooms</th>\n      <th>TotalBedrooms</th>\n      <th>Population</th>\n      <th>Households</th>\n      <th>MedianIncomeValue</th>\n      <th>MedianHouseValue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41</td>\n      <td>880</td>\n      <td>129</td>\n      <td>322</td>\n      <td>126</td>\n      <td>8.3252</td>\n      <td>452600</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21</td>\n      <td>7099</td>\n      <td>1106</td>\n      <td>2401</td>\n      <td>1138</td>\n      <td>8.3014</td>\n      <td>358500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52</td>\n      <td>1467</td>\n      <td>190</td>\n      <td>496</td>\n      <td>177</td>\n      <td>7.2574</td>\n      <td>352100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52</td>\n      <td>1274</td>\n      <td>235</td>\n      <td>558</td>\n      <td>219</td>\n      <td>5.6431</td>\n      <td>341300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52</td>\n      <td>1627</td>\n      <td>280</td>\n      <td>565</td>\n      <td>259</td>\n      <td>3.8462</td>\n      <td>342200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "This first snippet imports the library `numpy`, and then extracts data from the\npreviously loaded dataframe into numpy arrays. \n\nSince the model is a simple model with\nonly 20,640 rows of data that you are training, it is loaded in one turn. For larger training sets, you must load the data in several smaller epochs. \n\nThe\n`housing_data` contains the 20,460 values for each of the eight predictor variables,\nand the `housing_target` is the vector of 20,640 house values that this model\nis trained to predict.\n\nIf the following code cells generate an error message, please recitify the last two lines of the previous import code to \n<br><br>\n*df_data_1 = pd.read_csv(body)<br>\ndf_data_1.head()*", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import numpy as np\n\n# Make a numpy array from the dataframe\ndata = np.array([x for x in df_data_1.values])\n\n# Separate the 'predictors' (aka 'features') from the dependent variable (aka 'label') \n# that we will learn how to predict\nhousing_data = np.delete(data, 8, axis=1)\nhousing_target = np.delete(data, slice(0, 8), axis=1)", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "2"
                }
            }, 
            "outputs": [], 
            "execution_count": 2
        }, 
        {
            "source": "The two lines of code here are just a little housekeeping to prepare for the\nmachine learning step:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "m, n = housing_data.shape\nhousing_data_plus_bias = np.c_[np.ones((m, 1)), housing_data]", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "3"
                }
            }, 
            "outputs": [], 
            "execution_count": 3
        }, 
        {
            "source": "<a id=\"train\"></a>\n## Train the Model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Now, a relatively simple machine learning model is implemented here as a quick\ndemonstration of the elements of TensorFlow based machine learning with as\nlittle computing complexity as possible for clarity of comprehension. In essence, the data scientist describes what computations must\noccur, and then TensorFlow determines how to do the computations efficiently.\n\nYou're going to start by defining the 'flow' or computation graph that\nTensorFlow runs on. In this particular case, the compute tree for training a\nmultiple linear regression that uses the eight predictor variables and the housing\nvalue variable that the model learns to predict is defined. Here's what the code\nlooks like:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import tensorflow as tf\n\n# Make the compute graph\nX = tf.constant(housing_data_plus_bias, dtype=tf.float64, name=\"X\")\nXT = tf.transpose(X)\ny = tf.constant(housing_target.reshape(-1, 1), dtype=tf.float64, name=\"y\")\n\ntheta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "4"
                }
            }, 
            "outputs": [], 
            "execution_count": 4
        }, 
        {
            "source": "The `X` variable is the matrix of eight predictors by the 20,640 samples. `XT` is a\ntranspose that is needed in the linear regression computation. The `Y` variable\nis the dependent variable, and it is assigned to the 20,640 housing values in\nthe training data. The `theta` variable is the vector of linear regression\nequation coefficients that results from the series of matrix operations on the\nformula on the right side.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div class=\"alert alert-block alert-info\"> The previous code specifies the compute graph only, that is, the tensor flow. </div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "To perform the flow, run the following code. If you then run a line of code to\noutput `theta_value`, you can get an output similar to the output as shown here:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Run the compute graph\nwith tf.Session() as sess:\n    theta_value = theta.eval()\n    \n# For fun, show the linear regression model (i.e. the coefficients of the linear equation)\ntheta_value", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "5"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([[ -3.59402294e+06],\n       [ -4.28237438e+04],\n       [ -4.25767219e+04],\n       [  1.15630387e+03],\n       [ -8.18164928e+00],\n       [  1.13410689e+02],\n       [ -3.85350953e+01],\n       [  4.83082868e+01],\n       [  4.02485142e+04]])"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "<a id=\"save\"></a>\n## Save the Machine Learned Model to a Local data set\n\nThis is the machine learned linear regression model. It gives the coefficients\nof a linear equation that is best fit to the training data. Values for the eight\npredictor variables such as the age of the house and number of bedrooms can be\nused to predict a house value.\n\nBefore you are shown the prediction part, you must learn to save and reload the\nmodel in TensorFlow. Only after you save the model can you transport it to a\nproduction deployment environment, where you can restore it so that it can be used for inference (prediction).\n\nIf this is the first time that you run this notebook, it is recommended that you\nuse this line to create a subdirectory in data sets to save the TensorFlow model\nfrom this notebook:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Make a subdirectory in which to save the model\n!mkdir \"../datasets/Linear Regression\"", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "6"
                }
            }, 
            "outputs": [], 
            "execution_count": 6
        }, 
        {
            "source": "Then, to save the model, define a second simple TensorFlow compute model that\nassigns the `theta_value` vector to a variable named `model`. The following code\ncreates and runs this simple tensor flow, and then saves the result in\nthe subdirectory that is created previously.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Save the model\nmodel = tf.Variable(tf.constant(theta_value, dtype=tf.float64), name=\"model\")\n\ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()\n\nwith tf.Session() as saver_sess:\n    init.run()\n    theta_value = model.eval()\n    save_path = saver.save(saver_sess, \"../datasets/Linear Regression/Linear Regression.ckpt\")", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "7"
                }
            }, 
            "outputs": [], 
            "execution_count": 7
        }, 
        {
            "source": "The save method that is used here is practical since it is the same 'checkpoint'\nmethod that you would use if you were incrementally training a larger model in\nepochs. It's also useful to understand that what you are saving is the compute\ngraph, the tf.Variable TensorFlow variables, and values that are defined in the model\nthat you are checkpointing. In other words, what gets saved is specific to the\ntype of model that you are training because the type of model affects the\ncompute graph, or tensor flow, that you specified. In a neural net, for example,\nyou must save the structure of the net in addition to the weights and biases.\nFor a linear regression, you already know that the structure is a linear\nequation, so by saving the coefficients is sufficient. Regardless of what is\nbeing saved, TensorFlow saves four files, as shown by the line of code and\nits output:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# List the files that comprise the saved model\n!ls \"../datasets/Linear Regression\"", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "8"
                }
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "checkpoint\t\t\t\t    Linear Regression.ckpt.index\r\nLinear Regression.ckpt.data-00000-of-00001  Linear Regression.ckpt.meta\r\n"
                }
            ], 
            "execution_count": 8
        }, 
        {
            "source": "<a id=\"restore\"></a>\n## Restore the Machine Learned Model from the Local data set\n\nNow, suppose that you were to move these four files to a production deployment\nenvironment. The following is the code that you can use to reload the model to use for\ninference:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Restore the saved model \n# NOTE: This should run on inference service initialization, not on every inference\n\nsess_restore = tf.Session()\n\nsaver = tf.train.import_meta_graph('../datasets/Linear Regression/Linear Regression.ckpt.meta')\nsaver.restore(sess_restore,tf.train.latest_checkpoint('../datasets/Linear Regression/'))\n\ntheta_value = sess_restore.run('model:0')\n\nsess_restore.close()", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "9"
                }
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "INFO:tensorflow:Restoring parameters from ../datasets/Linear Regression/Linear Regression.ckpt\n"
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "# For fun, show the linear regression model again\ntheta_value", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "10"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 10, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([[ -3.59402294e+06],\n       [ -4.28237438e+04],\n       [ -4.25767219e+04],\n       [  1.15630387e+03],\n       [ -8.18164928e+00],\n       [  1.13410689e+02],\n       [ -3.85350953e+01],\n       [  4.83082868e+01],\n       [  4.02485142e+04]])"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "<a id=\"infer\"></a>\n## Infer by using the Restored Machine Learned Model\n\nFinally, you can perform inferences by using the `theta_value` vector. To simulate\nmaking a prediction, the zeroth row of the `housing_data` for the\nvalues of the predictor values is used. The `predicted_value` is initialized to\nthe constant coefficient of the linear equation, and then the remaining\ncoefficients of the theta_value are placed in `linear_coefficients` to make the\nloop easier to read. The loop then multiplies each predictor variable value\n`housing_data[0][j]` by the corresponding coefficient. (Each coefficient `c` in\nthe for loop iteration of `linear_coefficients` is, unfortunately, an array of\nsize 1, so `c[0]` is used to get the actual value of the coefficient.)\n\nIt's worth noting that, for a larger model, you can also use\nTensorFlow to perform the inference. But because this is a linear regression\nthat involves only nine coefficients, by using TensorFlow it might slow it down. \nStill, it is an easy tensor flow to write... an exercise for the reader!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Now we'll do an inference to predict a value with the model\n# We will use house_data[0] as if it had been received as input to the inference service\n\n# NOTE: This could be rewritten as TensorFlow code, though that would be more typical of \n#       larger models. At only 9 iterations, this would likely be slower as TensorFlow code\n\n# Start by setting the predicted value equal to the linear equation's constant term\npredicted_value = theta_value[0][0]\n\n# Get the coefficients of the features (i.e. exclude the constant term accounted for above)\ncoefficients = theta_value[1:]\n\n# For each feature (independent variable), add to the predicted value the product\n# of the coefficient for the feature (c = theta_value[j+1]) and the j^th feature of\n# the inference service input data (represented by housing_data[0])\nfor j, c in enumerate(coefficients):\n    predicted_value += c[0] * housing_data[0][j]", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "11"
                }
            }, 
            "outputs": [], 
            "execution_count": 11
        }, 
        {
            "source": "If you now run a line of Python code to see the value of `predicted_value`, you\nget output like the following:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# For fun, show the predicted value\npredicted_value", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "12"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "411111.09606514324"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 12
        }, 
        {
            "source": "Use the following code for when you want to erase the model training and start\nagain on a blank plate. Remove the `#` in front of the line of code and run the\ncell.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## For when you want to wipe out the training and do it again\n# !rm -rf \"../datasets/Linear Regression\"", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "15"
                }
            }, 
            "outputs": [], 
            "execution_count": 13
        }, 
        {
            "source": "<a id=\"measurement\"></a>\n## Measuring the Quality of the Trained Model\n\nNow you can measure the regression model quality with R squared. Begin by generate predictions for all of the housing data.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Now we'll see how to compute predictions for a batch of items by using all of the training data\npredicted_values = np.full((m), theta_value[0][0])\n\n# Get the coefficients of the features (i.e. exclude the constant term accounted for above)\ncoefficients = theta_value[1:]\n\n# For each of the m rows of housing data, update the predicted value (y) as follows:\n    # For each feature (independent variable), add to the predicted value the product\n    # of the coefficient for the feature (c = theta_value[j+1]) and the i^th row's\n    # housing data value for the jth feature\n\nfor i, x in enumerate(housing_data):\n    for j, c in enumerate(coefficients):\n        predicted_values[i] += c * x[j]\n        \npredicted_values", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 14, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([ 411111.09606514,  416144.49078677,  380432.65417531, ...,\n         25026.16974547,   37991.19625605,   55550.98309601])"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 14
        }, 
        {
            "source": "Now we'll get the actual dependent variable values into a flat array.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "y_actual = np.ndarray.flatten(housing_target)\ny_actual", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 15, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "array([ 452600.,  358500.,  352100., ...,   92300.,   84700.,   89400.])"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 15
        }, 
        {
            "source": "Now, we can calculated R squared using the scikit learn function, as this is how you'd normally do it.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from sklearn.metrics import r2_score\nR2 = r2_score(y_actual, predicted_values)\nR2", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 16, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.63710562292234463"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 16
        }, 
        {
            "source": "To give more insight into how R squared characterizes model quality, we can also do the math manually. We start with taking the average of the dependent variable.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "y_bar = np.mean(y_actual)\ny_bar", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "16"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 17, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "206855.81690891474"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 17
        }, 
        {
            "source": "Next, compute the data set variance from the mean (total sum of the squared\ndifferences).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "SStot = 0.0\nfor y_i in y_actual:\n    diff = float(y_i - y_bar)\n    SStot += (diff * diff)\nSStot", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "17"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 18, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "274831981936881.9"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "Now you can compute the amount that the regression models predicted values that vary\nfrom the mean. The total is the sum of squared differences between the predicted\nvalues and the mean.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "SSreg = 0.0\nfor f_i in predicted_values:\n    diff = float(f_i - y_bar)\n    SSreg += (diff * diff)\nSSreg", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "18"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 19, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "175097001050335.3"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 19
        }, 
        {
            "source": "The R squared is just the ratio. It gives the percentage of the variance from\nthe mean that is accounted for by using the regression model to predict values\nthe mean as the predicted value for any observation in the group.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "R_squared = SSreg / SStot\nR_squared", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "19"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 20, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.6371056229203638"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 20
        }, 
        {
            "source": "A second way to think about this is to consider the amount of remaining error,\nthat is, the amount of remaining or 'residual' variance between the actual data\npoints and the regression models predicted values.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "SSres = 0.0\nfor i, f_i in enumerate(predicted_values):\n    diff = float(f_i - y_actual[i])\n    SSres += (diff * diff)\nSSres", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "20"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 21, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "99734980886003.83"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 21
        }, 
        {
            "source": "So R squared can also be computed based on the percentage of leftover (residual)\nvariance.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "R_squared = 1.0 - SSres / SStot\nR_squared", 
            "cell_type": "code", 
            "metadata": {
                "attributes": {
                    "classes": [], 
                    "id": "", 
                    "n": "21"
                }
            }, 
            "outputs": [
                {
                    "execution_count": 22, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "0.6371056229223386"
                    }, 
                    "metadata": {}
                }
            ], 
            "execution_count": 22
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## Summary", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "You learned how to train a linear regression model by using the TensorFlow library and teaching it to predict house values with several predictor variables. Unlike a classification model that predicts a nominal variable (for example, classifying an input image as being one of several possible classes), data scientists train and use a regression model to predict the value of a continuous variable or high-valued ordinal variable (like a property valuation or a number of hours a patient needs in an intensive care unit). ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"links\"></a>\n## Related Links\n\n- <a href=\"https://datascience.ibm.com/\" target=\"_blank\">See Watson Studio</a><br>\n- <a href=\"https://www.ibm.com/developerworks/community/profiles/html/profileView.do?userid=060000VMNY&lang=en\" target=\"_blank\">Author's Blog on IBM Developer Works</a>\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"author\"></a>\n### Author\n\nJohn M. Boyer, IBM Global Chief Data Office", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Copyright \u00a9 IBM Corp. 2018. This notebook and its source code are released under the terms of the MIT License.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div style=\"background:#F5F7FA; height:100px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Want to do more?</span><span style=\"border: 1px solid #3d70b2;padding: 15px;float:right;margin-right:40px; color:#3d70b2; \"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n<span style=\"color:#5A6872;\"> Try out this notebook with your free trial of IBM Watson Studio.</span>\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
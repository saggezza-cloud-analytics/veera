{
    "nbformat_minor": 0, 
    "cells": [
        {
            "source": "# Use SQL with data in Hadoop Python\n\nThis notebook shows you how to query data stored in Hadoop using SQL. Apache Hadoop is an open source software framework used for storing and manipulating big data. The notebook shows you how you can use [IBM Big SQL](http://www.ibm.com/software/data/infosphere/hadoop/big-sql.html) to access data in Hadoop without having to learn new languages or skills.\n\n\n\nThe notebook uses a Big SQL sandbox environment to show you how to get started with SQL on Hadoop.\n\nTo query the data stored in Hadoop, you can use [IBM Big SQL](http://www.ibm.com/software/data/infosphere/hadoop/big-sql.html). This notebook shows you how to issue queries of any size on data stored in Hadoop.\n\n\n## Table of contents\n\n1. [What is Big SQL](#what_is_big_sql)\n1. [Load libraries](#load_libraries)\n1. [Access_data](#access_data)\n1. [Query data](#query_data)\n1. [Summary](#summary)\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"what_is_big_sql\"></a>\n## What is Big SQL?\n\n[IBM Big SQL](http://www.ibm.com/software/data/infosphere/hadoop/big-sql.html) is a data warehouse system for Hadoop that you can use to summarize, query, and analyze data. It provides standards-compliant SQL access to data in Hadoop.\n\nThis notebook shows you how to access the sandbox environment to get your own set of credentials.\n\n<a id=\"load_libraries\"></a>\n## Load libraries\n\n\nIn order to connect to a remote Hadoop cluster with Big SQL and then run SQL queries on data stored in Hadoop, the `ibm_db` library must be installed. The first time you run the notebook, if loading the library fails, you will need to install it with the following command:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "source": "!pip install --user ibm_db", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting ibm_db\n  Downloading ibm_db-2.0.7.tar.gz (553kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 563kB 2.0MB/s \n\u001b[?25hBuilding wheels for collected packages: ibm-db\n  Running setup.py bdist_wheel for ibm-db ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/s778-bfb6f75aebc10f-9bb95b1f072f/.cache/pip/wheels/d7/05/e2/d7b2f153bfbabcdf8af0fec36d78656142b5966cf6be091af3\nSuccessfully built ibm-db\nInstalling collected packages: ibm-db\nSuccessfully installed ibm-db-2.0.7\n"
                }
            ], 
            "metadata": {
                "scrolled": true, 
                "collapsed": false
            }
        }, 
        {
            "source": "Run the following cell to load the library once it is installed:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "source": "import ibm_db;", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "To connect to the database for this notebook, you need to get your own set of credentials.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"access_data\"></a>\n## Access data\n\nTo access the Big SQL technology preview sandbox environment, you need your own access credentials. To get your credentials:\n\n1. Sign up for a free Big SQL sandbox account on [IBM Analytics Demo Cloud](https://my.imdemocloud.com/users/sign_up).\n\n2. To set up your account, follow the instructions in the activation email that you are sent.\nNote: Your user name is different from your email address. For example, the user name for `jane.doe@example.com` might be `jane doe`. You will see your user name in the top-right corner of Demo Cloud when you're logged in.\n\n3. Log in to [IBM Analytics Demo Cloud](https://my.imdemocloud.com/users/sign_up) and click __Big SQL Technology Sandbox__. You are automatically approved to join.\n\n\nAdd your `username` and `password` between the quotation marks in the code cell below and run the cell:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "source": "username = \"\";\npassword = \"\"\ndatabase = \"bigsql\";\nhostname = \"iop-bi-master.imdemocloud.com\";\nport = \"32051\"", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "Finally, to connect to the Big SQL sandbox environment from the notebook, run the following cell:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "source": "conn_string = (\n      \"DRIVER={{IBM DB2 ODBC DRIVER}};\"\n      \"DATABASE={0};\"\n      \"HOSTNAME={1};\"\n      \"PORT={2};\"\n      \"PROTOCOL=TCPIP;\"\n      \"UID={3};\"\n      \"PWD={4};\").format(database, hostname, port, username, password);\n\nconn = ibm_db.connect(conn_string, \"\", \"\")", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "You are now connected to the Big SQL sandbox from the notebook.\n\nIf you saw an error, check that you filled in your user name and password correctly.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"query_data\"></a>\n## Query data\n\nIn this section, you will create a sample table, named `testTable`, load some data into it, and execute a query. Before you do this, you need to check if the table already exists in the sandbox environment, and if it does, remove it so that you can start from scratch.\n\nTo prepare and execute a single SQL statement, you will use the `ibm_db.exec_immediate()` function. The function takes the following arguments:\n* `connection`  \n  * A valid database connection resource returned from the `ibm_db.connect()` function.\n* `statement`  \n  * A string that contains the SQL statement. This string can include an XQuery expression that is wrapped by an XMLQUERY clause.\n  \n__Note:__ Big SQL has only one database called `bigsql` and you cannot create a new database. However, you can have your own schema, which defaults to your user name. When you connect to the database using your name and execute `CREATE HADOOP TABLE testTable`, a table called `YOUR_USER_NAME.testTable` is created under your schema. \n\nIn this notebook, you will use your schema. Run the next cell to ensure you are using your schema:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "source": "query = \"USE \"+username+\";\";\nibm_db.exec_immediate(conn, query);", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "Then run the next cell to remove the sample table `testTable` if it already exists to enable creating a new one:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "source": "query = \"DROP TABLE IF EXISTS testTable\"\nibm_db.exec_immediate(conn, query);", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "Now create a new `testTable` database table with two columns named `column1` and `column2`. To create the table in your schema, run the cell below:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "source": "query = \"CREATE HADOOP TABLE testTable (column1 INT, column2 STRING)\"\nibm_db.exec_immediate(conn, query);", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "Then insert some sample data into your `testTable` database table:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "source": "query = \"INSERT INTO testTable VALUES (1,'Text1'); \"\nibm_db.exec_immediate(conn, query);", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "Now retrieve and show this data:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "source": "query = \"SELECT * FROM testTable\";\nstmt = ibm_db.exec_immediate(conn, query);\ndictionary=ibm_db.fetch_both(stmt)\nprint \"The COLUMN1 value is : \", dictionary[\"COLUMN1\"]\nprint \"The COLUMN2 value is : \", dictionary[\"COLUMN2\"]", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The COLUMN1 value is :  1\nThe COLUMN2 value is :  Text1\n"
                }
            ], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "### Query big data\n\nIn this section you will use sample data that is provided in Big SQL by default. You will learn how to run queries and create reports about a fictional company named Sample Outdoor Company. \n\nThe GOSALESDW schema will be used. It contains fact tables for the following areas:\n\n* Distribution\n* Finance\n* Geography\n* Marketing\n* Organization\n* Personnel\n* Products\n* Retailers\n* Sales\n* Time\n\nRun the next cell to use the GOSALESDW schema and show the names and employee IDs of 10 employees:  ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "source": "query = \"use GOSALESDW;\";\nstmt = ibm_db.exec_immediate(conn, query);\nquery = \"select * from EMP_EMPLOYEE_DIM LIMIT 10\";\nstmt = ibm_db.exec_immediate(conn, query);\ndictionary = ibm_db.fetch_both(stmt)\nwhile dictionary != False:\n    print \"ID: \",  dictionary[\"EMPLOYEE_KEY\"] , \" -- Name: \", dictionary[\"EMPLOYEE_NAME\"]\n    dictionary = ibm_db.fetch_both(stmt)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "ID:  4001  -- Name:  \u00c9lizabeth Michel\nID:  4002  -- Name:  \u00c9mile Clermont\nID:  4003  -- Name:  \u00c9tienne Jauvin\nID:  4004  -- Name:  Frank Fuhlroth\nID:  4005  -- Name:  Gunter Erler\nID:  4006  -- Name:  Bj\u00f6rn Winkler\nID:  4007  -- Name:  Bj\u00f6rn Winkler\nID:  4008  -- Name:  Belinda Jansen-Velasquez\nID:  4009  -- Name:  Ellen Shapiro\nID:  4010  -- Name:  Maria Laponder\n"
                }
            ], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "You can improve the `SELECT` statement by adding a *predicate* to the second statement to return fewer rows. A predicate is a condition on a query that reduces and narrows the focus of the result. A predicate on a query with a multi-way join can improve the performance of the query.\n\nRun the next cell to narrow the search to return results from America only:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "source": "query = \"SELECT * FROM gosalesdw.go_region_dim WHERE region_en LIKE 'Amer%';\";\nstmt = ibm_db.exec_immediate(conn, query);\ndictionary = ibm_db.fetch_both(stmt)\ndictionary['REGION_CODE']\n", 
            "outputs": [
                {
                    "execution_count": 11, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "710"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "You can also run a query that returns the number of rows in a table. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "source": "query = \"SELECT COUNT(*) FROM gosalesdw.go_region_dim;\";\nstmt = ibm_db.exec_immediate(conn, query);\ndictionary = ibm_db.fetch_both(stmt)\ndictionary\n", 
            "outputs": [
                {
                    "execution_count": 12, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "{0: '21', '1': '21'}"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "To learn what products were ordered from Sample Outdoor Company, and by what method they were ordered, you must join the information from multiple tables in the `gosalesdw` database because it is a relational database where not everything is in one table.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "source": "lis=[]\nquery =\"\\\nSELECT pnumb.product_name, sales.quantity, \\\n  meth.order_method_en \\\nFROM \\\n  gosalesdw.sls_sales_fact sales, \\\n  gosalesdw.sls_product_dim prod, \\\n  gosalesdw.sls_product_lookup pnumb, \\\n  gosalesdw.sls_order_method_dim meth \\\nWHERE \\\n  pnumb.product_language='EN' \\\n  AND sales.product_key=prod.product_key \\\n  AND prod.product_number=pnumb.product_number \\\n  AND meth.order_method_key=sales.order_method_key LIMIT 10;\"\nstmt = ibm_db.exec_immediate(conn, query);\ndictionary = ibm_db.fetch_both(stmt)\nwhile dictionary != False:\n    lis.append(dictionary)\n    dictionary = ibm_db.fetch_both(stmt)\n    \nimport pandas as pd\npd.DataFrame(lis).head()", 
            "outputs": [
                {
                    "execution_count": 13, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "                       0    1            2 ORDER_METHOD_EN  \\\n0     Compact Relief Kit  313  Sales visit     Sales visit   \n1      Course Pro Putter  587    Telephone       Telephone   \n2  Blue Steel Max Putter  214    Telephone       Telephone   \n3      Course Pro Gloves  576    Telephone       Telephone   \n4         Glacier Deluxe  129  Sales visit     Sales visit   \n\n            PRODUCT_NAME  QUANTITY  \n0     Compact Relief Kit       313  \n1      Course Pro Putter       587  \n2  Blue Steel Max Putter       214  \n3      Course Pro Gloves       576  \n4         Glacier Deluxe       129  ", 
                        "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>ORDER_METHOD_EN</th>\n      <th>PRODUCT_NAME</th>\n      <th>QUANTITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Compact Relief Kit</td>\n      <td>313</td>\n      <td>Sales visit</td>\n      <td>Sales visit</td>\n      <td>Compact Relief Kit</td>\n      <td>313</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Course Pro Putter</td>\n      <td>587</td>\n      <td>Telephone</td>\n      <td>Telephone</td>\n      <td>Course Pro Putter</td>\n      <td>587</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Blue Steel Max Putter</td>\n      <td>214</td>\n      <td>Telephone</td>\n      <td>Telephone</td>\n      <td>Blue Steel Max Putter</td>\n      <td>214</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Course Pro Gloves</td>\n      <td>576</td>\n      <td>Telephone</td>\n      <td>Telephone</td>\n      <td>Course Pro Gloves</td>\n      <td>576</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Glacier Deluxe</td>\n      <td>129</td>\n      <td>Sales visit</td>\n      <td>Sales visit</td>\n      <td>Glacier Deluxe</td>\n      <td>129</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {
                "collapsed": false
            }
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## Summary\n\nIn this sample, you learned how to query data stored in Hadoop using SQL based on sample data in a Big SQL sandbox environment.\n\n<a id=\"resources\"></a>\n### Resources\n\nFor more information on Big SQL, see [Big SQL](https://www.ibm.com/support/knowledgecenter/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.bigsql.doc/doc/bsql_reference.html).", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Want to learn more?\n### Free courses on <a href=\"https://bigdatauniversity.com/courses/?utm_source=tutorial-dashdb-python&utm_medium=github&utm_campaign=bdu/\" rel=\"noopener noreferrer\" target=\"_blank\">Big Data University</a>: <a href=\"https://bigdatauniversity.com/courses/?utm_source=tutorial-dashdb-python&utm_medium=github&utm_campaign=bdu\" rel=\"noopener noreferrer\" target=\"_blank\"><img src = \"https://ibm.box.com/shared/static/xomeu7dacwufkoawbg3owc8wzuezltn6.png\" width=600px> </a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Authors\n\n**Saeed Aghabozorgi**, PhD, is a Data Scientist in IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge. He is a researcher in the data mining field and an expert in developing advanced analytic methods like machine learning and statistical modelling on large data sets.\n\n**Polong Lin** is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds an M.Sc. in Cognitive Psychology.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "Copyright \u00a9 2016, 2017 Big Data University. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT License</a>.", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }
}
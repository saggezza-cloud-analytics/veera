{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Copy data from multiple sources and load it to multiple targets using IBM Watson Data APIs\n\n## Introduction\nUse the IBM Watson Data Flows service to create and run data flows in a runtime engine. A flow can read data from a large variety of sources, process that data using predefined operations or custom code, and then write the data to one or more targets. The runtime engine can handle large amounts of data so it's ideally suited for reading, processing, and writing data at volume.\n\nThe sources and targets that are supported include both Cloud and on-premises offerings as well as data assets in projects. Cloud offerings include IBM Cloud Object Storage, Amazon S3, and Microsoft Azure SQL Database, among others. On-premises offerings include IBM Db2, Microsoft SQL Server, and Oracle, among others.\n\nIn the [Create and run a data flow with Watson Data APIs](https://dataplatform.ibm.com/exchange/public/entry/view/76deece1cf6f6f4bc3789678be94616d) notebook, you learned how to construct a single source data flow with Watson Data APIs. In this notebook, you'll build on that knowledge to create a data flow with multiple source and target connections.\n\nFor a list of the supported connection types and their properties, see [IBM Watson Data Flows Service - Data Asset and Connection Properties](https://api.dataplatform.ibm.com/v2/data_flows/doc/dataasset_and_connection_properties.html).\n\n#### Language and Spark Versions\nPython 3.5<br>\nSpark 2.1\n\n#### Prerequisites\nThe data flow created in this tutorial copies data from two tables stored in one [Db2 Warehouse](https://console.bluemix.net/catalog/services/db2-warehouse) instance:\n* GOSALES\\PRODUCTS\n* GOSALES\\ORDER_DETAILS\n\nYou can add Db2 Warehouse to your account from [Data Services](https://dataplatform.ibm.com/data/services?target=data-services&context=data) by selecting \"Add Service\" and then clicking \"Add\" on the \"Db2 Warehouse\" tile.\n\nOnce it's added, you can create a connection to Db2 Warehouse from the Data Services page. Simply select \"Create Connection\" from the action menu for Db2 Warehouse. The required connection details will be automatially populated for you.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Table of contents\n\n1. [Setup](#setup)<br>\n    1.1 [Environments](#setup1)<br>\n    1.2 [Project Token](#setup2)<br>\n    1.3 [Authorization](#setup3)<br>\n2. [Creating a multi source and target data flow](#create)<br>\n    2.1 [Retrieving a data asset](#create1)<br>\n    2.2 [Defining sources in a data flow](#create2)<br>\n    2.3 [Defining an operation in a data flow](#create3)<br>\n    2.4 [Defining targets in a data flow](#create4)<br>\n    2.5 [Creating the data flow](#create5)<br>\n    2.6 [Run the data flow](#run1)<br>\n    2.7 [Retrieve data flow run metrics](#run2)<br>\n4. [Resources](#resources)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 1. Setup", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "source": "import requests\nimport json\nimport uuid\n\ndef pretty_print(json_content):\n    parsed_json = json.loads(json_content)\n    print(json.dumps(parsed_json, indent=4, sort_keys=True))", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "####  <a id=\"setup1\"></a>1.1 Environments\nThe data flows service is currently available in the US South and UK regions of IBM Cloud. Use either environment URL in place of {service_URL} in the examples below:\n\n    US south https://api.dataplatform.ibm.com\n    UK https://api.eu-gb.dataplatform.ibm.com\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "source": "service_URL = \"https://api.dataplatform.ibm.com\"", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "####  <a id=\"setup2\"></a>1.2 Project Token\nInsert a project token from the action bar (more > Insert project token). Project tokens are used to access project resources like data sources and connections.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "source": "project_id = pc.projectID", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "####  <a id=\"setup3\"></a>1.3 Authorization\nAn IAM Bearer token is required in order to access IBM Watson Data APIs. For information on how to generate an IAM token see <a href=\"http://ibm.biz/wdp-api#getting\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "source": "# Replace <IAM Access Token> with your generated IAM Access Token\nauthorization = \"Bearer <IAM Access Token>\"", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "##  <a id=\"create\"></a>2. Creating a data flow with multiple sources and targets ##\nThe following example shows how to create a data flow that copies data from multiple source connections and loads data to multiple target connections.\n\n####  <a id=\"create1\"></a>2.1 Retrieving a connection ####\nBegin by retrieving a list of all connections in the Watson Studio project and then choosing one or more connections to use as the sources for the data flow. In this example, only one connection is required because we're copying data from two tables in the same database.\n\nFor further information on the connections service, see the Getting started / Connections section of the <a href=\"https://developer.ibm.com/api/view/watsondata-prod:watson-data:title-Watson_Data_API#doc\" target=\"_blank\" rel=\"noopener noreferrer\">IBM Watson Data API</a> documentation.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "source": "# GET https://api.dataplatform.ibm.com/v2/connections?project_id=<project_id>\n\nrequest = requests.get(service_URL + \"/v2/connections?project_id=\" + project_id + \"&limit=100\", headers={'Authorization': authorization})\npretty_print(request.text)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{\n    \"first\": {\n        \"href\": \"https://api.dataplatform.ibm.com/v2/connections?project_id=e5c41f96-85a0-4172-9232-b305e6240edb&limit=100\"\n    },\n    \"resources\": [\n        {\n            \"entity\": {\n                \"datasource_type\": \"cfdcb449-1204-44ba-baa6-9a8a878e6aa7\",\n                \"description\": \"IBM Db2 warehouse database on Cloud\",\n                \"flags\": [],\n                \"interaction_properties\": {\n                    \"source\": [\n                        {\n                            \"description\": \"The name of the schema that contains the table to read from\",\n                            \"hidden\": false,\n                            \"label\": \"Schema Name\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"schema_name\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        },\n                        {\n                            \"description\": \"The name of the table to read from\",\n                            \"hidden\": false,\n                            \"label\": \"Table Name\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"table_name\",\n                            \"readonly\": false,\n                            \"required\": true,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        },\n                        {\n                            \"description\": \"The SQL SELECT statement for retrieving data from the table\",\n                            \"hidden\": false,\n                            \"label\": \"Select Statement\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"select_statement\",\n                            \"readonly\": false,\n                            \"required\": true,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        },\n                        {\n                            \"default_value\": \"yes\",\n                            \"description\": \"Obtain the schema from the data source\",\n                            \"hidden\": false,\n                            \"label\": \"Infer Schema\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"rcp\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"boolean\",\n                            \"values\": []\n                        },\n                        {\n                            \"description\": \"The maximum number of rows to return\",\n                            \"hidden\": false,\n                            \"label\": \"Row Limit\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"row_limit\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"integer\",\n                            \"values\": []\n                        },\n                        {\n                            \"description\": \"The maximum number of bytes to return. Use any of these suffixes: KB, MB, GB, or TB\",\n                            \"hidden\": false,\n                            \"label\": \"Byte Limit\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"byte_limit\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        }\n                    ],\n                    \"target\": [\n                        {\n                            \"default_value\": \"insert\",\n                            \"description\": \"The mode for writing records to the target table\",\n                            \"hidden\": false,\n                            \"label\": \"Write Mode\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"write_mode\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"enum\",\n                            \"values\": [\n                                {\n                                    \"label\": \"Insert\",\n                                    \"value\": \"insert\"\n                                },\n                                {\n                                    \"label\": \"Merge\",\n                                    \"value\": \"merge\"\n                                },\n                                {\n                                    \"label\": \"Update\",\n                                    \"value\": \"update\"\n                                }\n                            ]\n                        },\n                        {\n                            \"description\": \"The name of the schema that contains the table to write to\",\n                            \"hidden\": false,\n                            \"label\": \"Schema Name\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"schema_name\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        },\n                        {\n                            \"description\": \"The name of the table to write to\",\n                            \"hidden\": false,\n                            \"label\": \"Table Name\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"table_name\",\n                            \"readonly\": false,\n                            \"required\": true,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        },\n                        {\n                            \"default_value\": \"append\",\n                            \"description\": \"The action to take on the target table, if it already exists, to handle the existing and new data sets\",\n                            \"hidden\": true,\n                            \"label\": \"Table Action\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"existing_table_action\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"enum\",\n                            \"values\": [\n                                {\n                                    \"label\": \"Append\",\n                                    \"value\": \"append\"\n                                },\n                                {\n                                    \"label\": \"Replace\",\n                                    \"value\": \"replace\"\n                                },\n                                {\n                                    \"label\": \"Truncate\",\n                                    \"value\": \"truncate\"\n                                },\n                                {\n                                    \"label\": \"Merge\",\n                                    \"value\": \"merge\"\n                                },\n                                {\n                                    \"label\": \"Update\",\n                                    \"value\": \"update\"\n                                }\n                            ]\n                        },\n                        {\n                            \"default_value\": \"append\",\n                            \"description\": \"The action to take on the target table to handle the new data set\",\n                            \"hidden\": false,\n                            \"label\": \"Table Action\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"table_action\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"enum\",\n                            \"values\": [\n                                {\n                                    \"label\": \"Append\",\n                                    \"value\": \"append\"\n                                },\n                                {\n                                    \"label\": \"Replace\",\n                                    \"value\": \"replace\"\n                                },\n                                {\n                                    \"label\": \"Truncate\",\n                                    \"value\": \"truncate\"\n                                }\n                            ]\n                        },\n                        {\n                            \"description\": \"The Create DDL statement for recreating the target table\",\n                            \"hidden\": false,\n                            \"label\": \"Create Statement\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"create_statement\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        },\n                        {\n                            \"description\": \"A comma seperated list of column names to override the primary key used during an update or merge.\",\n                            \"hidden\": false,\n                            \"label\": \"Key Column Names\",\n                            \"masked\": false,\n                            \"multiline\": false,\n                            \"name\": \"key_column_names\",\n                            \"readonly\": false,\n                            \"required\": false,\n                            \"tags\": [],\n                            \"type\": \"string\",\n                            \"values\": []\n                        }\n                    ]\n                },\n                \"name\": \"DB2WarehouseConnection\",\n                \"origin_country\": \"us\",\n                \"properties\": {\n                    \"database\": \"BLUDB\",\n                    \"host\": \"awh-yp-small03.services.dal.bluemix.net\",\n                    \"password\": \"********\",\n                    \"sg_service_url\": \"https://sgmanager.ng.bluemix.net\",\n                    \"username\": \"dash103285\"\n                },\n                \"rov\": {\n                    \"mode\": 0\n                }\n            },\n            \"metadata\": {\n                \"asset_id\": \"633b9935-4066-43ff-9412-efd21d441f81\",\n                \"asset_type\": \"connection\",\n                \"create_time\": \"2018-04-13T12:51:46.000Z\",\n                \"creator\": \"********\",\n                \"project_id\": \"e5c41f96-85a0-4172-9232-b305e6240edb\",\n                \"usage\": {\n                    \"access_count\": 0,\n                    \"last_access_time\": \"2018-04-13T12:51:46.870Z\",\n                    \"last_accessor\": \"********\",\n                    \"last_accessor_id\": \"ibmid-060000kubs\"\n                }\n            }\n        }\n    ],\n    \"total_count\": 1\n}\n"
                }
            ], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "In the response you can see that a connection exists with the ID `633b9935-4066-43ff-9412-efd21d441f81`. This is our connection. You'll need to use this later in the data flow you create.\n\n####  <a id=\"create2\"></a>2.2 Defining multiple sources in a data flow ####\nA data flow can contain one or more data sources. A data source is defined as a *binding node* in the data flow *pipeline*, which has one output and no inputs. The *binding node* must reference a data asset or connection. Depending on the type, additional *properties* might also need to be specified. Refer to [IBM Watson Data Flows Service - Data Asset and Connection Properties](https://api.dataplatform.ibm.com/v2/data_flows/doc/dataasset_and_connection_properties.html) to determine which properties are applicable for a given connection, and which of those are required. \n\nFor the following example, reference the connection you created earlier. The *binding nodes* for the data flow's sources are:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "source": "source_binding_node_1 = {\n    \"output\": {\n        \"id\": \"source1Output\"\n      },\n      \"connection\": {\n        \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\",\n        \"properties\": {\n          \"schema_name\": \"GOSALES\",\n          \"table_name\": \"PRODUCT\"\n        }\n      },\n      \"id\": \"source1\",\n      \"type\": \"binding\"\n}\nsource_binding_node_2 = {\n    \"output\": {\n        \"id\": \"source2Output\"\n      },\n      \"connection\": {\n        \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\",\n        \"properties\": {\n          \"schema_name\": \"GOSALES\",\n          \"table_name\": \"ORDER_DETAILS\"\n        }\n      },\n      \"id\": \"source2\",\n      \"type\": \"binding\"\n}", 
            "outputs": [], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "The `output` attribute declares the ID of the *output port* of these sources as `source1Output` & `source2Output` so that other nodes can read from them. You can see the connection with ID `633b9935-4066-43ff-9412-efd21d441f81` is being referenced in both cases because we're using the same connection for both source tables. This ID would be different for each source if we were using connections to two distinct sources.\n\n####  <a id=\"create3\"></a>2.3 Defining an operation in a multi-source data flow ####\nA data flow can contain zero or more operations, with a typical operation having one or more inputs and one or more outputs. An operation input is linked to the output of a source or another operation. An operation can also have additional parameters which define how the operation performs its work. An operation is defined as an *execution node* in the data flow *pipeline*. \n\nThe following example creates a sort operation for the column `PRODUCT_NUMBER` from `source1` only. A separate operation could also be added to `source2` or an operation could be applied that required both sources (for example, Join). The *execution node* for our sort operation is:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "source": "sort_operation = {  \n  \"id\":\"operation1\",\n  \"type\":\"execution_node\",\n  \"op\":\"com.ibm.wdp.transformer.FreeformCode\",\n  \"parameters\":{  \n     \"FREEFORM_CODE\": \"arrange(`PRODUCT_NUMBER`)\"\n  },\n  \"inputs\":[  \n     {  \n        \"id\":\"inputPort1\",\n        \"links\":[  \n           {  \n              \"node_id_ref\":\"source1\",\n              \"port_id_ref\":\"source1Output\"\n           }\n        ]\n     }\n  ],\n  \"outputs\":[  \n     {  \n        \"id\":\"outputPort1\"\n     }\n  ]\n}", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "The `inputs` attribute declares an *input port* with ID `inputPort1` which references the *output port* of the source node (node ID `source1` and port ID `source1Output`). \n\nFor this example, the operation is defined as a freeform operation, denoted by the `op` attribute value of `com.ibm.wdp.transformer.FreeformCode`. A freeform operation has only a single parameter named `FREEFORM_CODE` whose value is a snippet of Sparklyr code. In this snippet of code, a sort function is called and its argument is the column name to sort on, `PRODUCT_NUMBER`.\n\nThe `outputs` attribute declares the ID of the output of this operation as `outputPort1` so that other nodes can read from it.\n\n####  <a id=\"create4\"></a>2.4 Defining multiple targets in a data flow ####\nA data flow can contain zero or more targets. A target is defined as a *binding node* in the data flow *pipeline* which has one input and no outputs. As with the source, the *binding node* must reference either a connection or a data asset. When using a connection as a target, specify the connection ID and the required properties for your connection type.\n\nIn the following example, we're writing to a different schema in the same connection that we created earlier. Connections are referenced by IDs. The *binding nodes* for the data flow's targets are:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "source": "target_binding_node_1 = {\n  \"input\": {\n    \"link\": {\n      \"node_id_ref\": \"operation1\",\n      \"port_id_ref\": \"outputPort1\"\n    },\n    \"id\": \"targetInput1\"\n  },\n  \"connection\": {\n    \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\",\n    \"properties\": {\n      \"write_mode\": \"insert\",\n      \"schema_name\": \"DASH103285\",\n      \"table_name\": \"PRODUCT_SORTED\",\n      \"table_action\": \"truncate\"\n    }\n  },\n  \"id\": \"target1\",\n  \"type\": \"binding\"\n}\ntarget_binding_node_2 = {\n  \"input\": {\n    \"link\": {\n      \"node_id_ref\": \"source2\",\n      \"port_id_ref\": \"source2Output\"\n    },\n    \"id\": \"targetInput2\"\n  },\n  \"connection\": {\n    \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\",\n    \"properties\": {\n      \"write_mode\": \"insert\",\n      \"schema_name\": \"DASH103285\",\n      \"table_name\": \"ORDER_DETAILS_LATEST\",\n      \"table_action\": \"truncate\"\n    }\n  },\n  \"id\": \"target2\",\n  \"type\": \"binding\"\n}", 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "The `input` attribute in each *binding_node* declares an *input port* with ID. `target1Input` references the *output port* of the operation node (node ID `operation1` and port ID `outputPort1`), while `target2input` references the *source output* of `source2`, because there was no operation applied to that source. The ID of the connection is used in both *binding_nodes*, along with the required properties for the connection type. Here, we're writing to the same connection as the source, but the data flow can target any connection that exists in the project.\n\n####  <a id=\"create5\"></a>2.5 Creating the data flow ####\nPutting it all together, you can now call the API to create the data flow with the following POST method:\n\n```POST https://{service_URL}/v2/data_flows```\n\nThe new data flow can be stored in a catalog or project. Use either the `catalog_id` **or** `project_id` query parameter, depending on where you want to store the data flow. An example request to create a data flow is shown below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "source": "dataflow = {  \n   \"name\":\"my_dataflow_\" + str(uuid.uuid4()),\n   \"pipeline\":{  \n      \"doc_type\":\"pipeline\",\n      \"version\":\"1.0\",\n      \"primary_pipeline\":\"pipeline1\",\n      \"pipelines\":[  \n         {  \n            \"id\":\"pipeline1\",\n            \"runtime\":\"Spark\",\n            \"nodes\":[  \n            ]\n         }\n      ]\n   }\n}\n\ndataflow[\"pipeline\"][\"pipelines\"][0][\"nodes\"].append(source_binding_node_1)\ndataflow[\"pipeline\"][\"pipelines\"][0][\"nodes\"].append(source_binding_node_2)\ndataflow[\"pipeline\"][\"pipelines\"][0][\"nodes\"].append(sort_operation)\ndataflow[\"pipeline\"][\"pipelines\"][0][\"nodes\"].append(target_binding_node_1)\ndataflow[\"pipeline\"][\"pipelines\"][0][\"nodes\"].append(target_binding_node_2)\n\ndataflow_response = requests.post(service_URL + \"/v2/data_flows?project_id=\" + project_id, headers={'Authorization': authorization}, json=dataflow)\ndata_flow_id = json.loads(dataflow_response.text)[\"metadata\"][\"asset_id\"]\npretty_print(dataflow_response.text)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{\n    \"entity\": {\n        \"name\": \"my_dataflow_5497f887-eea3-464a-98b8-9af95a45351f\",\n        \"pipeline\": {\n            \"doc_type\": \"pipeline\",\n            \"id\": \"4835bf16-5c40-43d6-a5fa-478a1bd69f39\",\n            \"pipelines\": [\n                {\n                    \"id\": \"pipeline1\",\n                    \"nodes\": [\n                        {\n                            \"connection\": {\n                                \"properties\": {\n                                    \"schema_name\": \"GOSALES\",\n                                    \"table_name\": \"PRODUCT\"\n                                },\n                                \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\"\n                            },\n                            \"id\": \"source1\",\n                            \"output\": {\n                                \"id\": \"source1Output\"\n                            },\n                            \"type\": \"binding\"\n                        },\n                        {\n                            \"connection\": {\n                                \"properties\": {\n                                    \"schema_name\": \"GOSALES\",\n                                    \"table_name\": \"ORDER_DETAILS\"\n                                },\n                                \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\"\n                            },\n                            \"id\": \"source2\",\n                            \"output\": {\n                                \"id\": \"source2Output\"\n                            },\n                            \"type\": \"binding\"\n                        },\n                        {\n                            \"id\": \"operation1\",\n                            \"inputs\": [\n                                {\n                                    \"id\": \"inputPort1\",\n                                    \"links\": [\n                                        {\n                                            \"node_id_ref\": \"source1\",\n                                            \"port_id_ref\": \"source1Output\"\n                                        }\n                                    ]\n                                }\n                            ],\n                            \"op\": \"com.ibm.wdp.transformer.FreeformCode\",\n                            \"outputs\": [\n                                {\n                                    \"id\": \"outputPort1\"\n                                }\n                            ],\n                            \"parameters\": {\n                                \"FREEFORM_CODE\": \"arrange(`PRODUCT_NUMBER`)\"\n                            },\n                            \"type\": \"execution_node\"\n                        },\n                        {\n                            \"connection\": {\n                                \"properties\": {\n                                    \"schema_name\": \"DASH103285\",\n                                    \"table_action\": \"truncate\",\n                                    \"table_name\": \"PRODUCT_SORTED\",\n                                    \"write_mode\": \"insert\"\n                                },\n                                \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\"\n                            },\n                            \"id\": \"target1\",\n                            \"input\": {\n                                \"id\": \"targetInput1\",\n                                \"link\": {\n                                    \"node_id_ref\": \"operation1\",\n                                    \"port_id_ref\": \"outputPort1\"\n                                }\n                            },\n                            \"type\": \"binding\"\n                        },\n                        {\n                            \"connection\": {\n                                \"properties\": {\n                                    \"schema_name\": \"DASH103285\",\n                                    \"table_action\": \"truncate\",\n                                    \"table_name\": \"ORDER_DETAILS_LATEST\",\n                                    \"write_mode\": \"insert\"\n                                },\n                                \"ref\": \"633b9935-4066-43ff-9412-efd21d441f81\"\n                            },\n                            \"id\": \"target2\",\n                            \"input\": {\n                                \"id\": \"targetInput2\",\n                                \"link\": {\n                                    \"node_id_ref\": \"source2\",\n                                    \"port_id_ref\": \"source2Output\"\n                                }\n                            },\n                            \"type\": \"binding\"\n                        }\n                    ],\n                    \"runtime\": \"Spark\"\n                }\n            ],\n            \"primary_pipeline\": \"pipeline1\",\n            \"version\": \"1.0\"\n        },\n        \"tags\": []\n    },\n    \"metadata\": {\n        \"asset_id\": \"0d4c8d74-7388-4a67-9e04-d04afd24ae77\",\n        \"asset_type\": \"data_flow\",\n        \"create_time\": \"2018-04-16T13:42:55.000Z\",\n        \"creator\": \"********\",\n        \"creator_id\": \"ibmid-060000kubs\",\n        \"href\": \"https://api.dataplatform.ibm.com/v2/data_flows/0d4c8d74-7388-4a67-9e04-d04afd24ae77?project_id=e5c41f96-85a0-4172-9232-b305e6240edb\",\n        \"project_id\": \"e5c41f96-85a0-4172-9232-b305e6240edb\",\n        \"usage\": {\n            \"access_count\": 0,\n            \"last_access_time\": \"2018-04-16T13:42:55.480Z\",\n            \"last_accessor\": \"********\",\n            \"last_accessor_id\": \"ibmid-060000kubs\",\n            \"last_modification_time\": \"2018-04-16T13:42:55.480Z\",\n            \"last_modifier\": \"********\",\n            \"last_modifier_id\": \"ibmid-060000kubs\"\n        }\n    }\n}\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "The response shows that the data flow was created with an ID of `cdfb87f2-91f8-4c6e-9886-d43d992362ee`, which you will need later to run the data flow.\n\n#### <a id=\"run1\"></a>2.6 Run the data flow ####\nTo run a data flow, call the following POST API:\n\n```\nPOST https://{service_URL}/v2/data_flows/{data_flow_id}/runs?project_id={project_id}\n```\n\nThe value of `data_flow_id` is the `metadata.asset_id` from your data flow. An example response from this API call could be:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "source": "dataflow_run_response = requests.post(service_URL + \"/v2/data_flows/\" + data_flow_id + \"/runs?project_id=\" + project_id, headers={'Authorization': authorization}, json={})\ndata_flow_run_id = json.loads(dataflow_run_response.text)[\"metadata\"][\"asset_id\"]\npretty_print(dataflow_run_response.text)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{\n    \"entity\": {\n        \"configuration\": {},\n        \"data_flow_ref\": \"0d4c8d74-7388-4a67-9e04-d04afd24ae77\",\n        \"name\": \"my_dataflow_5497f887-eea3-464a-98b8-9af95a45351f\",\n        \"rov\": {\n            \"members\": [],\n            \"mode\": 0\n        },\n        \"state\": \"starting\",\n        \"tags\": []\n    },\n    \"metadata\": {\n        \"asset_id\": \"10a7260c-1387-4893-9461-1245aad8494d\",\n        \"asset_type\": \"data_flow_run\",\n        \"create_time\": \"2018-04-16T13:43:15.000Z\",\n        \"creator\": \"********\",\n        \"creator_id\": \"ibmid-060000kubs\",\n        \"href\": \"https://api.dataplatform.ibm.com/v2/data_flows/0d4c8d74-7388-4a67-9e04-d04afd24ae77/runs/10a7260c-1387-4893-9461-1245aad8494d?project_id=e5c41f96-85a0-4172-9232-b305e6240edb\",\n        \"project_id\": \"e5c41f96-85a0-4172-9232-b305e6240edb\",\n        \"usage\": {\n            \"access_count\": 0,\n            \"last_access_time\": \"2018-04-16T13:43:15.415Z\",\n            \"last_accessor\": \"********\",\n            \"last_accessor_id\": \"ibmid-060000kubs\",\n            \"last_modification_time\": \"2018-04-16T13:43:15.415Z\",\n            \"last_modifier\": \"********\",\n            \"last_modifier_id\": \"ibmid-060000kubs\"\n        }\n    }\n}\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "#### <a id=\"run2\"></a>2.7 Retrieve data flow run metrics####\n\nTo retrieve a breakdown of the latest data flow metrics broken down by source and target, call the following GET method:\n\n`GET https://{service_URL}/v2/data_flows/{data_flow_id}/runs/{data_flow_run_id}/metrics?project_id={project_id}`\n\nThe value of data_flow_id is the metadata.asset_id from your data flow. The value of data_flow_run_id is the metadata.asset_id from your data flow run. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "source": "dataflow_run_metrics = requests.get(service_URL + \"/v2/data_flows/\" + data_flow_id + \"/runs/\" + data_flow_run_id + \"/metrics?project_id=\" + project_id, headers={'Authorization': authorization})\npretty_print(dataflow_run_metrics.text)", 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "{\n    \"details\": [\n        {\n            \"connection_type\": \"cfdcb449-1204-44ba-baa6-9a8a878e6aa7\",\n            \"disposition\": \"source\",\n            \"metrics\": {\n                \"bytes_read\": 30524,\n                \"fields\": [],\n                \"fields_read\": 9,\n                \"rows_read\": 548\n            },\n            \"node_ref\": \"source1\",\n            \"pipeline_ref\": \"pipeline1\",\n            \"port_ref\": \"source1Output\",\n            \"type\": \"binding\"\n        },\n        {\n            \"connection_type\": \"cfdcb449-1204-44ba-baa6-9a8a878e6aa7\",\n            \"disposition\": \"source\",\n            \"metrics\": {\n                \"bytes_read\": 61997197,\n                \"fields\": [],\n                \"fields_read\": 9,\n                \"rows_read\": 446023\n            },\n            \"node_ref\": \"source2\",\n            \"pipeline_ref\": \"pipeline1\",\n            \"port_ref\": \"source2Output\",\n            \"type\": \"binding\"\n        },\n        {\n            \"connection_type\": \"cfdcb449-1204-44ba-baa6-9a8a878e6aa7\",\n            \"disposition\": \"target\",\n            \"metrics\": {\n                \"bytes_written\": 15262,\n                \"fields\": [\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PRODUCT_NUMBER\",\n                        \"nullable\": false,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"BASE_PRODUCT_NUMBER\",\n                        \"nullable\": true,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 6.0,\n                            \"max_length\": 26.0,\n                            \"values\": []\n                        },\n                        \"name\": \"INTRODUCTION_DATE\",\n                        \"nullable\": true,\n                        \"type\": \"timestamp\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 6.0,\n                            \"max_length\": 26.0,\n                            \"values\": []\n                        },\n                        \"name\": \"DISCONTINUED_DATE\",\n                        \"nullable\": true,\n                        \"type\": \"timestamp\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PRODUCT_TYPE_CODE\",\n                        \"nullable\": false,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PRODUCT_COLOR_CODE\",\n                        \"nullable\": true,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PRODUCT_SIZE_CODE\",\n                        \"nullable\": true,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PRODUCT_BRAND_CODE\",\n                        \"nullable\": true,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 60.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PRODUCT_IMAGE\",\n                        \"nullable\": true,\n                        \"type\": \"varchar\"\n                    }\n                ],\n                \"fields_written\": 9,\n                \"rows_written\": 274\n            },\n            \"node_ref\": \"target1\",\n            \"pipeline_ref\": \"pipeline1\",\n            \"port_ref\": \"targetInput1\",\n            \"type\": \"binding\"\n        },\n        {\n            \"connection_type\": \"cfdcb449-1204-44ba-baa6-9a8a878e6aa7\",\n            \"disposition\": \"target\",\n            \"metrics\": {\n                \"bytes_written\": 61997197,\n                \"fields\": [\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"ORDER_DETAIL_CODE\",\n                        \"nullable\": false,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"ORDER_NUMBER\",\n                        \"nullable\": false,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 6.0,\n                            \"max_length\": 26.0,\n                            \"values\": []\n                        },\n                        \"name\": \"SHIP_DATE\",\n                        \"nullable\": false,\n                        \"type\": \"timestamp\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PRODUCT_NUMBER\",\n                        \"nullable\": false,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 10.0,\n                            \"values\": []\n                        },\n                        \"name\": \"PROMOTION_CODE\",\n                        \"nullable\": false,\n                        \"type\": \"integer\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 0.0,\n                            \"max_length\": 19.0,\n                            \"values\": []\n                        },\n                        \"name\": \"QUANTITY\",\n                        \"nullable\": false,\n                        \"type\": \"bigint\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 2.0,\n                            \"max_length\": 19.0,\n                            \"values\": []\n                        },\n                        \"name\": \"UNIT_COST\",\n                        \"nullable\": true,\n                        \"type\": \"decimal\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 2.0,\n                            \"max_length\": 19.0,\n                            \"values\": []\n                        },\n                        \"name\": \"UNIT_PRICE\",\n                        \"nullable\": true,\n                        \"type\": \"decimal\"\n                    },\n                    {\n                        \"metadata\": {\n                            \"decimal_scale\": 2.0,\n                            \"max_length\": 19.0,\n                            \"values\": []\n                        },\n                        \"name\": \"UNIT_SALE_PRICE\",\n                        \"nullable\": true,\n                        \"type\": \"decimal\"\n                    }\n                ],\n                \"fields_written\": 9,\n                \"rows_written\": 446023\n            },\n            \"node_ref\": \"target2\",\n            \"pipeline_ref\": \"pipeline1\",\n            \"port_ref\": \"targetInput2\",\n            \"type\": \"binding\"\n        }\n    ],\n    \"state\": \"finished\",\n    \"summary\": {\n        \"completed_date\": \"2018-04-16T13:44:16.287Z\",\n        \"engine_completed_date\": \"2018-04-16T13:44:15.900Z\",\n        \"engine_compute_units\": 0.96,\n        \"engine_elapsed_secs\": 47,\n        \"engine_started_date\": \"2018-04-16T13:43:28.050Z\",\n        \"engine_status_date\": \"2018-04-16T13:44:15.903Z\",\n        \"engine_submitted_date\": \"2018-04-16T13:43:17.961Z\",\n        \"total_bytes_read\": 62027721,\n        \"total_bytes_written\": 62012459,\n        \"total_rows_read\": 446571,\n        \"total_rows_written\": 446297\n    }\n}\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "## <a id=\"resources\"></a>3. Resources ##\nFor further information, see <a href=\"http://ibm.biz/wdp-api\" target=\"_blank\" rel=\"noopener noreferrer\">IBM Watson Data API</a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Author\n**Wesley Williams** & **Damian Cummins**, Cloud Application Developers with the Data Refinery and IBM Watson teams at IBM. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Copyright \u00a9 IBM Corp. 2018. This notebook and its source code are released under the terms of the MIT License.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}